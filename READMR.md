# ğŸ“± Human Activity Recognition using Smartphone Accelerometer Data  

![Python](https://img.shields.io/badge/Python-3.8%2B-blue.svg) 
![TensorFlow](https://img.shields.io/badge/TensorFlow-2.x-orange.svg)
![License](https://img.shields.io/badge/License-MIT-green.svg)

## ğŸ“– Overview
This project implements **Human Activity Recognition (HAR)** using data collected from the accelerometers and gyroscopes of smartphones.  
We use the **UCI HAR Dataset**, apply preprocessing, and build a **Machine Learning model** to classify activities such as:  
- ğŸš¶ Walking  
- ğŸƒ Walking Upstairs  
- ğŸ§‘â€ğŸ¦½ Walking Downstairs  
- ğŸª‘ Sitting  
- ğŸ›ï¸ Lying  
- ğŸ§ Standing  

The system demonstrates the power of **Data Science + Machine Learning** in recognizing human movements for potential applications in:
- Fitness tracking ğŸ‹ï¸â€â™‚ï¸
- Elderly monitoring ğŸ§“
- Healthcare diagnostics ğŸ¥
- Human-computer interaction ğŸ’»

---

## ğŸ“‚ Dataset
We use the **UCI HAR Dataset**:
- **Link:** [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/human+activity+recognition+using+smartphones)
- 30 subjects performed six activities while wearing a smartphone on the waist.
- The dataset includes **3-axial linear acceleration** and **3-axial angular velocity** data.  

ğŸ“Š **Training set:** 7352 samples  
ğŸ“Š **Test set:** 2947 samples  

---

## âš™ï¸ Project Structure
